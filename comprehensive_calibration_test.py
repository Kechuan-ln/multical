#!/usr/bin/env python3
"""
PrimeColoræ ‡å®šæ”¹è¿› - ç»¼åˆæ‰¹é‡æµ‹è¯•
æµ‹è¯•æ‰€æœ‰primecolorå›¾åƒï¼Œå¯¹æ¯”ä¸åŒé…ç½®å’Œå¢å¼ºæ–¹æ³•çš„æ•ˆæœ
"""

import cv2
import numpy as np
import os
import sys
import json
import time
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import List, Dict, Tuple
from collections import defaultdict
import matplotlib.pyplot as plt
from tqdm import tqdm

# æ·»åŠ multicalè·¯å¾„
sys.path.insert(0, '/Volumes/FastACIS/annotation_pipeline/multical')


@dataclass
class TestConfig:
    """æµ‹è¯•é…ç½®"""
    name: str
    yaml_config: str
    enhance_method: str = None  # None, 'clahe', 'gamma', 'hybrid'

    def __str__(self):
        enhance = f"_{self.enhance_method}" if self.enhance_method else ""
        return f"{self.name}{enhance}"


@dataclass
class DetectionResult:
    """å•å¼ å›¾åƒçš„æ£€æµ‹ç»“æœ"""
    image_name: str
    config_name: str
    num_markers: int
    num_corners: int
    success: bool
    min_points: int
    detection_time_ms: float

    def to_dict(self):
        return asdict(self)


class ComprehensiveCalibrationTest:
    """ç»¼åˆæ ‡å®šæµ‹è¯•"""

    def __init__(self, image_dir: str):
        self.image_dir = Path(image_dir)
        self.results = []

        # å®šä¹‰æµ‹è¯•é…ç½®
        self.test_configs = [
            TestConfig("original",
                      "/Volumes/FastACIS/annotation_pipeline/multical/asset/charuco_b1_2.yaml"),
            TestConfig("original",
                      "/Volumes/FastACIS/annotation_pipeline/multical/asset/charuco_b1_2.yaml",
                      "clahe"),
            TestConfig("optimized",
                      "/Volumes/FastACIS/annotation_pipeline/multical/asset/charuco_b1_2_dark.yaml"),
            TestConfig("optimized",
                      "/Volumes/FastACIS/annotation_pipeline/multical/asset/charuco_b1_2_dark.yaml",
                      "clahe"),
            TestConfig("optimized",
                      "/Volumes/FastACIS/annotation_pipeline/multical/asset/charuco_b1_2_dark.yaml",
                      "gamma"),
            TestConfig("optimized",
                      "/Volumes/FastACIS/annotation_pipeline/multical/asset/charuco_b1_2_dark.yaml",
                      "hybrid"),
        ]

        # ChArUcoæ¿é…ç½®ï¼ˆB1æ¿ï¼‰
        self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_7X7_250)
        self.board = cv2.aruco.CharucoBoard_create(7, 9, 0.095, 0.075, self.aruco_dict)
        self.theoretical_max_corners = 48  # B1æ¿ç†è®ºæœ€å¤§è§’ç‚¹æ•°

    def load_aruco_params(self, yaml_path: str) -> cv2.aruco.DetectorParameters:
        """ä»YAMLåŠ è½½ArUcoå‚æ•°"""
        import yaml

        with open(yaml_path, 'r') as f:
            config = yaml.safe_load(f)

        aruco_params_dict = config.get('aruco_params', {})
        params = cv2.aruco.DetectorParameters_create()

        for key, value in aruco_params_dict.items():
            if hasattr(params, key):
                setattr(params, key, value)

        return params, config.get('common', {}).get('min_points', 20)

    def enhance_image(self, image, method: str):
        """å›¾åƒå¢å¼º"""
        if method is None:
            return image

        if method == 'clahe':
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
            l_enhanced = clahe.apply(l)
            enhanced_lab = cv2.merge([l_enhanced, a, b])
            return cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)

        elif method == 'gamma':
            gamma = 1.5
            inv_gamma = 1.0 / gamma
            table = np.array([((i / 255.0) ** inv_gamma) * 255
                             for i in np.arange(0, 256)]).astype("uint8")
            return cv2.LUT(image, table)

        elif method == 'hybrid':
            # Gammaæ ¡æ­£
            gamma = 1.3
            inv_gamma = 1.0 / gamma
            table = np.array([((i / 255.0) ** inv_gamma) * 255
                             for i in np.arange(0, 256)]).astype("uint8")
            gamma_corrected = cv2.LUT(image, table)

            # é™å™ª
            denoised = cv2.fastNlMeansDenoisingColored(gamma_corrected, None, 5, 5, 7, 21)

            # CLAHE
            lab = cv2.cvtColor(denoised, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
            l_enhanced = clahe.apply(l)
            enhanced_lab = cv2.merge([l_enhanced, a, b])
            return cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)

        return image

    def detect_charuco(self, image, config: TestConfig) -> DetectionResult:
        """æ£€æµ‹ChArUcoæ¿"""
        start_time = time.time()

        # åŠ è½½å‚æ•°
        aruco_params, min_points = self.load_aruco_params(config.yaml_config)

        # å›¾åƒå¢å¼º
        processed = self.enhance_image(image, config.enhance_method)

        # è½¬ç°åº¦
        if len(processed.shape) == 3:
            gray = cv2.cvtColor(processed, cv2.COLOR_BGR2GRAY)
        else:
            gray = processed

        # æ£€æµ‹markers
        marker_corners, marker_ids, _ = cv2.aruco.detectMarkers(
            gray, self.aruco_dict, parameters=aruco_params)

        num_markers = len(marker_ids) if marker_ids is not None else 0
        num_corners = 0

        # æ’å€¼è§’ç‚¹
        if marker_ids is not None and len(marker_ids) > 0:
            _, corners, ids = cv2.aruco.interpolateCornersCharuco(
                marker_corners, marker_ids, gray, self.board)
            num_corners = len(corners) if corners is not None else 0

        detection_time = (time.time() - start_time) * 1000  # ms

        return DetectionResult(
            image_name="",  # åé¢å¡«å……
            config_name=str(config),
            num_markers=num_markers,
            num_corners=num_corners,
            success=(num_corners >= min_points),
            min_points=min_points,
            detection_time_ms=detection_time
        )

    def test_single_image(self, image_path: Path) -> List[DetectionResult]:
        """æµ‹è¯•å•å¼ å›¾åƒçš„æ‰€æœ‰é…ç½®"""
        image = cv2.imread(str(image_path))
        if image is None:
            return []

        results = []
        for config in self.test_configs:
            result = self.detect_charuco(image, config)
            result.image_name = image_path.name
            results.append(result)

        return results

    def run_batch_test(self, pattern: str = "*.png", limit: int = None):
        """æ‰¹é‡æµ‹è¯•"""
        image_files = sorted(self.image_dir.glob(pattern))

        if limit:
            image_files = image_files[:limit]

        total_images = len(image_files)

        if total_images == 0:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é… {pattern} çš„å›¾åƒ")
            return

        print(f"\n{'='*80}")
        print(f"ç»¼åˆæ ‡å®šæµ‹è¯•")
        print(f"{'='*80}")
        print(f"å›¾åƒç›®å½•: {self.image_dir}")
        print(f"æµ‹è¯•å›¾åƒæ•°: {total_images}")
        print(f"æµ‹è¯•é…ç½®æ•°: {len(self.test_configs)}")
        print(f"æ€»æµ‹è¯•æ•°: {total_images * len(self.test_configs)}")
        print(f"{'='*80}\n")

        # æ˜¾ç¤ºæµ‹è¯•é…ç½®
        print("æµ‹è¯•é…ç½®:")
        for i, config in enumerate(self.test_configs, 1):
            enhance_str = f" + {config.enhance_method.upper()}" if config.enhance_method else ""
            print(f"  {i}. {config.name}{enhance_str}")
        print()

        # æ‰¹é‡æµ‹è¯•ï¼ˆæ˜¾ç¤ºè¿›åº¦æ¡ï¼‰
        for image_file in tqdm(image_files, desc="æµ‹è¯•è¿›åº¦", unit="å¼ "):
            results = self.test_single_image(image_file)
            self.results.extend(results)

        print("\nâœ… æµ‹è¯•å®Œæˆï¼\n")

    def generate_statistics(self) -> Dict:
        """ç”Ÿæˆç»Ÿè®¡æ•°æ®"""
        stats = defaultdict(lambda: {
            'total': 0,
            'success': 0,
            'total_markers': 0,
            'total_corners': 0,
            'detection_times': []
        })

        for result in self.results:
            config = result.config_name
            stats[config]['total'] += 1
            if result.success:
                stats[config]['success'] += 1
            stats[config]['total_markers'] += result.num_markers
            stats[config]['total_corners'] += result.num_corners
            stats[config]['detection_times'].append(result.detection_time_ms)

        # è®¡ç®—å¹³å‡å€¼å’Œç™¾åˆ†æ¯”
        summary = {}
        for config, data in stats.items():
            total = data['total']
            if total == 0:
                continue

            summary[config] = {
                'total_images': total,
                'success_count': data['success'],
                'success_rate': data['success'] / total * 100,
                'avg_markers': data['total_markers'] / total,
                'avg_corners': data['total_corners'] / total,
                'corner_detection_rate': (data['total_corners'] / total) / self.theoretical_max_corners * 100,
                'avg_detection_time_ms': np.mean(data['detection_times']),
                'std_detection_time_ms': np.std(data['detection_times'])
            }

        return summary

    def print_summary(self, stats: Dict):
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
        print(f"\n{'='*100}")
        print("æµ‹è¯•ç»“æœæ±‡æ€»")
        print(f"{'='*100}\n")

        # è¡¨å¤´
        print(f"{'é…ç½®':<30} {'æˆåŠŸç‡':<12} {'å¹³å‡Marker':<12} {'å¹³å‡è§’ç‚¹':<12} {'æ£€æµ‹ç‡%':<12} {'å¹³å‡è€—æ—¶(ms)'}")
        print("-" * 100)

        # æŒ‰é…ç½®æ’åºè¾“å‡º
        for config in sorted(stats.keys()):
            data = stats[config]
            print(f"{config:<30} "
                  f"{data['success_rate']:>6.1f}% ({data['success_count']}/{data['total_images']})   "
                  f"{data['avg_markers']:>6.1f}        "
                  f"{data['avg_corners']:>6.1f}        "
                  f"{data['corner_detection_rate']:>6.1f}%      "
                  f"{data['avg_detection_time_ms']:>6.1f}")

        print("\n" + "="*100)

        # æ”¹è¿›å¯¹æ¯”
        self.print_improvement_analysis(stats)

    def print_improvement_analysis(self, stats: Dict):
        """æ‰“å°æ”¹è¿›åˆ†æ"""
        print("\næ”¹è¿›æ•ˆæœåˆ†æ:")
        print("-" * 100)

        # æ‰¾åˆ°baselineï¼ˆoriginalæ— å¢å¼ºï¼‰
        baseline_key = None
        for key in stats.keys():
            if 'original' in key and 'clahe' not in key and 'gamma' not in key and 'hybrid' not in key:
                baseline_key = key
                break

        if not baseline_key:
            print("æœªæ‰¾åˆ°baselineé…ç½®")
            return

        baseline = stats[baseline_key]

        print(f"\nåŸºå‡†é…ç½®: {baseline_key}")
        print(f"  - æˆåŠŸç‡: {baseline['success_rate']:.1f}%")
        print(f"  - å¹³å‡è§’ç‚¹: {baseline['avg_corners']:.1f}")
        print(f"  - æ£€æµ‹ç‡: {baseline['corner_detection_rate']:.1f}%")

        print(f"\nä¸åŸºå‡†å¯¹æ¯”:")
        print(f"{'é…ç½®':<35} {'æˆåŠŸç‡å˜åŒ–':<15} {'è§’ç‚¹æ•°å˜åŒ–':<15} {'æ£€æµ‹ç‡å˜åŒ–'}")
        print("-" * 100)

        for config, data in sorted(stats.items()):
            if config == baseline_key:
                continue

            success_diff = data['success_rate'] - baseline['success_rate']
            corners_diff = data['avg_corners'] - baseline['avg_corners']
            detection_diff = data['corner_detection_rate'] - baseline['corner_detection_rate']

            print(f"{config:<35} "
                  f"{success_diff:>+6.1f}%         "
                  f"{corners_diff:>+6.1f}         "
                  f"{detection_diff:>+6.1f}%")

        # æ‰¾å‡ºæœ€ä½³é…ç½®
        best_config = max(stats.items(), key=lambda x: x[1]['success_rate'])
        print(f"\nğŸ† æœ€ä½³é…ç½®: {best_config[0]}")
        print(f"   æˆåŠŸç‡: {best_config[1]['success_rate']:.1f}%")
        print(f"   æ¯”åŸºå‡†æå‡: +{best_config[1]['success_rate'] - baseline['success_rate']:.1f}%")
        print(f"   å¹³å‡è§’ç‚¹: {best_config[1]['avg_corners']:.1f} (åŸºå‡†: {baseline['avg_corners']:.1f})")

        print("="*100)

    def save_results(self, output_file: str):
        """ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSON"""
        data = {
            'test_info': {
                'image_dir': str(self.image_dir),
                'total_images': len(set(r.image_name for r in self.results)),
                'configs_tested': len(self.test_configs),
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            },
            'results': [r.to_dict() for r in self.results],
            'statistics': self.generate_statistics()
        }

        with open(output_file, 'w') as f:
            json.dump(data, f, indent=2)

        print(f"\nâœ… è¯¦ç»†ç»“æœå·²ä¿å­˜: {output_file}")

    def plot_comparison(self, output_file: str):
        """ç”Ÿæˆå¯è§†åŒ–å¯¹æ¯”å›¾"""
        stats = self.generate_statistics()

        configs = list(stats.keys())
        success_rates = [stats[c]['success_rate'] for c in configs]
        avg_corners = [stats[c]['avg_corners'] for c in configs]

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

        # å­å›¾1: æˆåŠŸç‡å¯¹æ¯”
        colors = ['#FF6B6B' if 'original' in c and not any(x in c for x in ['clahe', 'gamma', 'hybrid'])
                 else '#4ECDC4' if 'optimized' in c
                 else '#95E1D3' for c in configs]

        bars1 = ax1.bar(range(len(configs)), success_rates, color=colors, alpha=0.8)
        ax1.set_xlabel('é…ç½®', fontsize=12)
        ax1.set_ylabel('æˆåŠŸç‡ (%)', fontsize=12)
        ax1.set_title('ChArUcoæ£€æµ‹æˆåŠŸç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax1.set_xticks(range(len(configs)))
        ax1.set_xticklabels(configs, rotation=45, ha='right', fontsize=9)
        ax1.grid(axis='y', alpha=0.3)

        # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
        for bar, rate in zip(bars1, success_rates):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{rate:.1f}%',
                    ha='center', va='bottom', fontsize=9)

        # å­å›¾2: å¹³å‡è§’ç‚¹æ•°å¯¹æ¯”
        bars2 = ax2.bar(range(len(configs)), avg_corners, color=colors, alpha=0.8)
        ax2.set_xlabel('é…ç½®', fontsize=12)
        ax2.set_ylabel('å¹³å‡è§’ç‚¹æ•°', fontsize=12)
        ax2.set_title('å¹³å‡æ£€æµ‹è§’ç‚¹æ•°å¯¹æ¯” (ç†è®ºæœ€å¤§: 48)', fontsize=14, fontweight='bold')
        ax2.set_xticks(range(len(configs)))
        ax2.set_xticklabels(configs, rotation=45, ha='right', fontsize=9)
        ax2.axhline(y=48, color='r', linestyle='--', alpha=0.5, label='ç†è®ºæœ€å¤§å€¼')
        ax2.grid(axis='y', alpha=0.3)
        ax2.legend()

        # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
        for bar, corners in zip(bars2, avg_corners):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    f'{corners:.1f}',
                    ha='center', va='bottom', fontsize=9)

        plt.tight_layout()
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {output_file}")

        # å…³é—­å›¾è¡¨ä»¥é‡Šæ”¾å†…å­˜
        plt.close()

    def generate_report(self, report_file: str):
        """ç”ŸæˆMarkdownæ ¼å¼çš„æµ‹è¯•æŠ¥å‘Š"""
        stats = self.generate_statistics()

        # æ‰¾baseline
        baseline_key = None
        for key in stats.keys():
            if 'original' in key and not any(x in key for x in ['clahe', 'gamma', 'hybrid']):
                baseline_key = key
                break

        baseline = stats.get(baseline_key, {})

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# PrimeColoræ ‡å®šæ”¹è¿›æµ‹è¯•æŠ¥å‘Š\n\n")
            f.write(f"**æµ‹è¯•æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**å›¾åƒç›®å½•**: `{self.image_dir}`\n\n")
            f.write(f"**æµ‹è¯•å›¾åƒæ•°**: {len(set(r.image_name for r in self.results))}\n\n")
            f.write(f"**æµ‹è¯•é…ç½®æ•°**: {len(self.test_configs)}\n\n")

            f.write("---\n\n")
            f.write("## æµ‹è¯•ç»“æœæ±‡æ€»\n\n")

            # è¡¨æ ¼
            f.write("| é…ç½® | æˆåŠŸç‡ | å¹³å‡Marker | å¹³å‡è§’ç‚¹ | æ£€æµ‹ç‡% | å¹³å‡è€—æ—¶(ms) |\n")
            f.write("|------|--------|------------|----------|---------|-------------|\n")

            for config in sorted(stats.keys()):
                data = stats[config]
                f.write(f"| {config} | "
                       f"{data['success_rate']:.1f}% ({data['success_count']}/{data['total_images']}) | "
                       f"{data['avg_markers']:.1f} | "
                       f"{data['avg_corners']:.1f} | "
                       f"{data['corner_detection_rate']:.1f}% | "
                       f"{data['avg_detection_time_ms']:.1f} |\n")

            f.write("\n---\n\n")
            f.write("## æ”¹è¿›æ•ˆæœåˆ†æ\n\n")

            if baseline_key:
                f.write(f"### åŸºå‡†é…ç½®: `{baseline_key}`\n\n")
                f.write(f"- æˆåŠŸç‡: **{baseline['success_rate']:.1f}%**\n")
                f.write(f"- å¹³å‡è§’ç‚¹: **{baseline['avg_corners']:.1f}**\n")
                f.write(f"- æ£€æµ‹ç‡: **{baseline['corner_detection_rate']:.1f}%**\n\n")

                f.write("### å„é…ç½®ä¸åŸºå‡†å¯¹æ¯”\n\n")
                f.write("| é…ç½® | æˆåŠŸç‡å˜åŒ– | è§’ç‚¹æ•°å˜åŒ– | æ£€æµ‹ç‡å˜åŒ– |\n")
                f.write("|------|-----------|-----------|----------|\n")

                for config, data in sorted(stats.items()):
                    if config == baseline_key:
                        continue

                    success_diff = data['success_rate'] - baseline['success_rate']
                    corners_diff = data['avg_corners'] - baseline['avg_corners']
                    detection_diff = data['corner_detection_rate'] - baseline['corner_detection_rate']

                    f.write(f"| {config} | "
                           f"{success_diff:+.1f}% | "
                           f"{corners_diff:+.1f} | "
                           f"{detection_diff:+.1f}% |\n")

                # æœ€ä½³é…ç½®
                best_config = max(stats.items(), key=lambda x: x[1]['success_rate'])
                f.write(f"\n### ğŸ† æ¨èé…ç½®\n\n")
                f.write(f"**æœ€ä½³é…ç½®**: `{best_config[0]}`\n\n")
                f.write(f"- æˆåŠŸç‡: **{best_config[1]['success_rate']:.1f}%**\n")
                f.write(f"- æ¯”åŸºå‡†æå‡: **+{best_config[1]['success_rate'] - baseline['success_rate']:.1f}%**\n")
                f.write(f"- å¹³å‡è§’ç‚¹: **{best_config[1]['avg_corners']:.1f}** (åŸºå‡†: {baseline['avg_corners']:.1f})\n")
                f.write(f"- æ£€æµ‹ç‡: **{best_config[1]['corner_detection_rate']:.1f}%** (åŸºå‡†: {baseline['corner_detection_rate']:.1f}%)\n\n")

            f.write("---\n\n")
            f.write("## ä½¿ç”¨å»ºè®®\n\n")

            best = max(stats.items(), key=lambda x: x[1]['success_rate'])

            if 'optimized' in best[0]:
                f.write("âœ… **å»ºè®®ä½¿ç”¨ä¼˜åŒ–é…ç½®**\n\n")
                f.write("åœ¨ `run_gopro_primecolor_calibration.py` ä¸­ä¿®æ”¹:\n")
                f.write("```python\n")
                f.write('BOARD_CONFIG = "./asset/charuco_b1_2_dark.yaml"\n')
                f.write("```\n\n")

            if best[1].get('success_rate', 0) - baseline.get('success_rate', 0) > 30:
                f.write("ğŸ“ˆ **æ”¹è¿›æ˜¾è‘—ï¼**å»ºè®®ç«‹å³åº”ç”¨æœ€ä½³é…ç½®é‡æ–°æ ‡å®š\n\n")
            elif best[1].get('success_rate', 0) - baseline.get('success_rate', 0) > 10:
                f.write("ğŸ“Š **æœ‰ä¸€å®šæ”¹è¿›**ï¼Œå»ºè®®å°è¯•åº”ç”¨ä¼˜åŒ–é…ç½®\n\n")
            else:
                f.write("âš ï¸ **æ”¹è¿›æœ‰é™**ï¼Œå¯èƒ½éœ€è¦ä»ç¡¬ä»¶å±‚é¢æ”¹å–„ï¼ˆå¢åŠ å…‰ç…§ã€æ›´æ¢æ ‡å®šæ¿ç­‰ï¼‰\n\n")

        print(f"âœ… æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description='PrimeColoræ ‡å®šæ”¹è¿› - ç»¼åˆæ‰¹é‡æµ‹è¯•',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:

1. æµ‹è¯•æ‰€æœ‰å›¾åƒï¼ˆæ¨èï¼‰:
   python comprehensive_calibration_test.py

2. æµ‹è¯•å‰50å¼ å›¾åƒï¼ˆå¿«é€ŸéªŒè¯ï¼‰:
   python comprehensive_calibration_test.py --limit 50

3. æŒ‡å®šè¾“å‡ºç›®å½•:
   python comprehensive_calibration_test.py --output test_results/

4. è‡ªå®šä¹‰å›¾åƒç›®å½•:
   python comprehensive_calibration_test.py --dir /path/to/primecolor/frames
        """
    )

    parser.add_argument('--dir', '-d',
                       default="/Volumes/FastACIS/GoPro/gopro_primecolor_extrinsic /calibration_output/extrinsics/frames/primecolor",
                       help='primecolorå›¾åƒç›®å½•')
    parser.add_argument('--limit', '-l', type=int,
                       help='é™åˆ¶æµ‹è¯•å›¾åƒæ•°é‡ï¼ˆç”¨äºå¿«é€ŸéªŒè¯ï¼‰')
    parser.add_argument('--pattern', '-p', default='*.png',
                       help='æ–‡ä»¶åŒ¹é…æ¨¡å¼')
    parser.add_argument('--output', '-o', default='.',
                       help='è¾“å‡ºç›®å½•')

    args = parser.parse_args()

    # æ£€æŸ¥å›¾åƒç›®å½•
    if not os.path.exists(args.dir):
        print(f"âŒ å›¾åƒç›®å½•ä¸å­˜åœ¨: {args.dir}")
        return 1

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    # è¿è¡Œæµ‹è¯•
    tester = ComprehensiveCalibrationTest(args.dir)
    tester.run_batch_test(pattern=args.pattern, limit=args.limit)

    # ç”Ÿæˆç»Ÿè®¡
    stats = tester.generate_statistics()
    tester.print_summary(stats)

    # ä¿å­˜ç»“æœ
    timestamp = time.strftime('%Y%m%d_%H%M%S')
    json_file = output_dir / f"calibration_test_results_{timestamp}.json"
    plot_file = output_dir / f"calibration_test_comparison_{timestamp}.png"
    report_file = output_dir / f"calibration_test_report_{timestamp}.md"

    tester.save_results(str(json_file))
    tester.plot_comparison(str(plot_file))
    tester.generate_report(str(report_file))

    print(f"\n{'='*80}")
    print("æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*80}")
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"   - JSONç»“æœ: {json_file}")
    print(f"   - å¯è§†åŒ–å›¾: {plot_file}")
    print(f"   - æµ‹è¯•æŠ¥å‘Š: {report_file}")
    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print(f"   1. æŸ¥çœ‹æµ‹è¯•æŠ¥å‘Š: cat {report_file}")
    print(f"   2. æŸ¥çœ‹å¯è§†åŒ–å›¾: open {plot_file}")
    print(f"   3. å¦‚æœæ”¹è¿›æ˜¾è‘—ï¼Œåº”ç”¨æ¨èé…ç½®é‡æ–°æ ‡å®š")
    print()

    return 0


if __name__ == "__main__":
    sys.exit(main())
